{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer, Adafactor, AdamW\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "import sys\n",
    "torch.bfloat16 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 12 11:06:04 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  On   | 00000000:04:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    24W / 250W |      8MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    24W / 250W |      8MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-PCIE...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    26W / 250W |      8MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-PCIE...  On   | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    24W / 250W |      8MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-PCIE...  On   | 00000000:0C:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    23W / 250W |      8MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-PCIE...  On   | 00000000:0D:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    34W / 250W |   1563MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla V100-PCIE...  On   | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    25W / 250W |      8MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla V100-PCIE...  On   | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    25W / 250W |      8MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1698      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A      1698      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A      1698      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A      1698      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    4   N/A  N/A      1698      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    5   N/A  N/A      1698      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    5   N/A  N/A   2157677      C   python                           1555MiB |\n",
      "|    6   N/A  N/A      1698      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    7   N/A  N/A      1698      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv('../data/news_summary.csv',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>headlines</th>\n",
       "      <th>read_more</th>\n",
       "      <th>text</th>\n",
       "      <th>ctext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chhavi Tyagi</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in...</td>\n",
       "      <td>http://www.hindustantimes.com/india-news/raksh...</td>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "      <td>The Daman and Diu administration on Wednesday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Daisy Mowke</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Malaika slams user who trolled her for 'divorc...</td>\n",
       "      <td>http://www.hindustantimes.com/bollywood/malaik...</td>\n",
       "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
       "      <td>From her special numbers to TV?appearances, Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arshiya Chopra</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>'Virgin' now corrected to 'Unmarried' in IGIMS...</td>\n",
       "      <td>http://www.hindustantimes.com/patna/bihar-igim...</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sumedha Sehra</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Aaj aapne pakad liya: LeT man Dujana before be...</td>\n",
       "      <td>http://indiatoday.intoday.in/story/abu-dujana-...</td>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aarushi Maheshwari</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Hotel staff to get training to spot signs of s...</td>\n",
       "      <td>http://indiatoday.intoday.in/story/sex-traffic...</td>\n",
       "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
       "      <td>Hotels in Mumbai and other Indian cities are t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author                  date  \\\n",
       "0        Chhavi Tyagi  03 Aug 2017,Thursday   \n",
       "1         Daisy Mowke  03 Aug 2017,Thursday   \n",
       "2      Arshiya Chopra  03 Aug 2017,Thursday   \n",
       "3       Sumedha Sehra  03 Aug 2017,Thursday   \n",
       "4  Aarushi Maheshwari  03 Aug 2017,Thursday   \n",
       "\n",
       "                                           headlines  \\\n",
       "0  Daman & Diu revokes mandatory Rakshabandhan in...   \n",
       "1  Malaika slams user who trolled her for 'divorc...   \n",
       "2  'Virgin' now corrected to 'Unmarried' in IGIMS...   \n",
       "3  Aaj aapne pakad liya: LeT man Dujana before be...   \n",
       "4  Hotel staff to get training to spot signs of s...   \n",
       "\n",
       "                                           read_more  \\\n",
       "0  http://www.hindustantimes.com/india-news/raksh...   \n",
       "1  http://www.hindustantimes.com/bollywood/malaik...   \n",
       "2  http://www.hindustantimes.com/patna/bihar-igim...   \n",
       "3  http://indiatoday.intoday.in/story/abu-dujana-...   \n",
       "4  http://indiatoday.intoday.in/story/sex-traffic...   \n",
       "\n",
       "                                                text  \\\n",
       "0  The Administration of Union Territory Daman an...   \n",
       "1  Malaika Arora slammed an Instagram user who tr...   \n",
       "2  The Indira Gandhi Institute of Medical Science...   \n",
       "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...   \n",
       "4  Hotels in Maharashtra will train their staff t...   \n",
       "\n",
       "                                               ctext  \n",
       "0  The Daman and Diu administration on Wednesday ...  \n",
       "1  From her special numbers to TV?appearances, Bo...  \n",
       "2  The Indira Gandhi Institute of Medical Science...  \n",
       "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...  \n",
       "4  Hotels in Mumbai and other Indian cities are t...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data['news'] = data_raw['ctext']\n",
    "data['summary'] = data_raw['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Daman and Diu administration on Wednesday ...</td>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From her special numbers to TV?appearances, Bo...</td>\n",
       "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hotels in Mumbai and other Indian cities are t...</td>\n",
       "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news  \\\n",
       "0  The Daman and Diu administration on Wednesday ...   \n",
       "1  From her special numbers to TV?appearances, Bo...   \n",
       "2  The Indira Gandhi Institute of Medical Science...   \n",
       "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...   \n",
       "4  Hotels in Mumbai and other Indian cities are t...   \n",
       "\n",
       "                                             summary  \n",
       "0  The Administration of Union Territory Daman an...  \n",
       "1  Malaika Arora slammed an Instagram user who tr...  \n",
       "2  The Indira Gandhi Institute of Medical Science...  \n",
       "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...  \n",
       "4  Hotels in Maharashtra will train their staff t...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4514 entries, 0 to 4513\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   news     4396 non-null   object\n",
      " 1   summary  4514 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 70.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:2') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_loss(model,val_loader):\n",
    "    temp = model.eval()\n",
    "    num_batches = 0\n",
    "    loss_sum = 0\n",
    "    for batch in val_loader:\n",
    "        encoder_input = batch[\"encoder_input\"].to(device)\n",
    "        encoder_attention_mask = batch[\"encoder_attention_masks\"].to(device)\n",
    "        decoder_input = batch[\"decoder_input\"].to(device)\n",
    "        decoder_output = batch[\"decoder_output\"].to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids=encoder_input,\n",
    "                         attention_mask=encoder_attention_mask,\n",
    "                         decoder_input_ids=decoder_input,\n",
    "                        labels=decoder_output)\n",
    "        loss_sum += output.loss.item()\n",
    "        num_batches +=1\n",
    "    return loss_sum/num_batches\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(data.news)\n",
    "y = list(data.summary)\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name =   '../model/pegasus_news_summary' #'google/pegasus-xsum'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gives a dictionary of tensors\n",
    "input_enc_train = tokenizer.prepare_seq2seq_batch(X_train, truncation=True, padding='longest', return_tensors=\"pt\")\n",
    "target_enc_train = tokenizer.prepare_seq2seq_batch(y_train, truncation=True, padding='longest', return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_enc_val = tokenizer.prepare_seq2seq_batch(X_test, truncation=True, padding='longest', return_tensors=\"pt\")\n",
    "target_enc_val = tokenizer.prepare_seq2seq_batch(y_test, truncation=True, padding='longest', return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsSummaryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,input_encodings,target_encodings):\n",
    "        self.input_encodings = input_encodings\n",
    "        self.target_encodings = target_encodings\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        data = {}\n",
    "        data[\"encoder_input\"]=self.input_encodings[\"input_ids\"][idx]\n",
    "        data[\"encoder_attention_masks\"] = self.input_encodings[\"attention_mask\"][idx]\n",
    "        data[\"decoder_output\"] = self.target_encodings[\"input_ids\"][idx]\n",
    "        decoder_input = self.target_encodings.input_ids[idx]\n",
    "        #For right shifting input\n",
    "        decoder_input = torch.roll(decoder_input,1,-1)\n",
    "        decoder_input[0] = torch.tensor(0)\n",
    "        data[\"decoder_input\"] = decoder_input\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.target_encodings.input_ids.shape[0]\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NewsSummaryDataset(input_enc_train,target_enc_train)\n",
    "val_dataset = NewsSummaryDataset(input_enc_val,target_enc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_BATCH_SIZE=8\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,shuffle=True,batch_size=INPUT_BATCH_SIZE)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,shuffle=True,batch_size=INPUT_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "x = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = AdamW(model.parameters(),lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 0.942607: 100%|██████████| 440/440 [07:18<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 1.072890"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 0.936294: 100%|██████████| 440/440 [07:12<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 1.069782"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train loss: 0.930634: 100%|██████████| 440/440 [07:24<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 1.066664"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train loss: 0.924967: 100%|██████████| 440/440 [07:23<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 1.064443"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train loss: 0.919701: 100%|██████████| 440/440 [07:24<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 1.062250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train loss: 0.914822: 100%|██████████| 440/440 [07:25<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 1.060834"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train loss: 0.909529: 100%|██████████| 440/440 [07:26<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 1.058897"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train loss: 0.905031: 100%|██████████| 440/440 [07:19<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 1.057524"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Train loss: 0.900296: 100%|██████████| 440/440 [07:25<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 1.056268"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train loss: 0.895962: 100%|██████████| 440/440 [07:25<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 1.055066"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train loss: 0.891695: 100%|██████████| 440/440 [07:18<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 1.054102"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Train loss: 0.887606: 100%|██████████| 440/440 [07:24<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 1.053197"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Train loss: 0.883236: 100%|██████████| 440/440 [07:21<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 1.052608"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Train loss: 0.878913: 100%|██████████| 440/440 [07:22<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 1.051757"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Train loss: 0.874781: 100%|██████████| 440/440 [07:23<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 1.051069"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Train loss: 0.870452: 100%|██████████| 440/440 [07:23<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 1.050568"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Train loss: 0.866729: 100%|██████████| 440/440 [07:17<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 1.050332"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Train loss: 0.862927: 100%|██████████| 440/440 [07:24<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 1.049702"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Train loss: 0.859234: 100%|██████████| 440/440 [07:20<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 1.049763"
     ]
    }
   ],
   "source": [
    "#34 epochs till now\n",
    "EPOCH = 20\n",
    "prev_val_loss = 10000\n",
    "for epoch in range(EPOCH):\n",
    "    pbar = tqdm.tqdm(train_loader)\n",
    "    loss_sum =0\n",
    "    num_batch=0\n",
    "    for batch in pbar:\n",
    "        optim.zero_grad()\n",
    "        encoder_input = batch[\"encoder_input\"].to(device)\n",
    "        encoder_attention_mask = batch[\"encoder_attention_masks\"].to(device)\n",
    "        decoder_input = batch[\"decoder_input\"].to(device)\n",
    "        decoder_output = batch[\"decoder_output\"].to(device)\n",
    "        output = model(input_ids=encoder_input,\n",
    "                       attention_mask=encoder_attention_mask,\n",
    "                       decoder_input_ids=decoder_input,\n",
    "                       labels=decoder_output)\n",
    "        loss = output[0]\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        loss_sum += loss.item()\n",
    "        num_batch+=1\n",
    "        pbar.set_description(\"Epoch: %s, Train loss: %f\"%(epoch,loss_sum/num_batch))\n",
    "    \n",
    "    val_loss = get_val_loss(model,val_loader)\n",
    "    sys.stdout.write(\"         Val loss: %f\"%val_loss)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    #Breaking criteria\n",
    "    if prev_val_loss < val_loss:\n",
    "        break\n",
    "\n",
    "    prev_val_loss = val_loss\n",
    "\n",
    "    #saving model checkpoint\n",
    "    model.save_pretrained(\"../model/pegasus_news_summary\")\n",
    "    tokenizer.save_pretrained(\"../model/pegasus_news_summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_enc_test = tokenizer.prepare_seq2seq_batch(X_test[2:10], truncation=True, padding='longest', return_tensors=\"pt\").to(device)\n",
    "translated = model.generate(**input_enc_test)\n",
    "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Be it biscuits or nut crackers, drug peddlers are lacing them with LSD and selling them at higher price, agencies dealing with narcotics claimed. \"Most of the drugs, especially LSD, coming from Germany, India are being coated on eatables,\" they added. Notably, earlier LSD-laced sugar cubes were seized'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=6\n",
    "tgt_text[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Believe it or not, eatables laced with LSD are the emerging modus operandi followed by drug peddlers across the country, agencies dealing against narcotics claimed. Be it biscuits or nut crackers, drug peddlers are lacing them with LSD and selling them at higher price.The revelation came days after Task Force sleuths arrested nine people, including two Nigerians, in two separate cases at Masab Tank and Banjara Hills in Hyderabad. Along with 300 grams of cocaine, 42 grams of MDMA and three biscuits laced with LSD were recovered.According to sources, during interrogation, they told police that to save themselves from being caught at the airport, they started coating LSD on eatables such as biscuits and nut crackers. They further told police that this is not the first time they have laced eatables with LSD. \"Most of the drugs, especially LSD, coming from Germany to India are being coated on eatables,\" they reportedly confessed.LSD LACED EATABLESThe officers said that earlier LSD-laced sugar cubes were seized, but this is the first time drugs in biscuits were found. \"These biscuits were detected and seized only because the peddlers were carrying another drug as well, which was detected in the scanning machine,\" an officer involved in the investigation said.After recording the confessional statement, the inputs were shared with the narcotics department. Also, security agencies at the airports, including CISF, have been alerted about the new modus operandiSpeaking to Mail Today, a senior officer of the narcotics department said, \"It is very difficult to identify adultered eatables and eatables laced with LSD. But officers scanning passengers\\' luggage at the airport have been asked to keep tight vigil on eatables in their bags. Not only this, but they have been advised to check biscuits or nut crackers if they are in small quantity.\"Sources also said peddlers - mostly from African countries - have been carrying small consignments which they hide between the clothes or in false cavities in their bags.\"They also carry nut cracker packets in their hand bags to avoid suspicion. They keep the seal open and tend to eat some of them to fool security officers. Those arrested hid the eatables laced with LSD in a small false cavity inside the packet to fool the officers,\" a source said, quoting one of the confessional statements.Meanwhile, preliminary interrogation and analysis of cell phone data of the peddlers revealed they might have sold drugs to more than 100 people in the last one and half years.\"Most buyers are young, especially college students,\" said an officer in the Task Force. In a separate case, West Zone Task Force arrested three people and seized 11 LSD bots and three cell phones. The accused are P Revanth, Irfan Najeeb Khan and Zain Khan.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[2:10][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Drug peddlers are coating biscuits and nut crackers with Lysergic acid diethylamide (LSD) drug to avoid being caught at airports, Task Force officials said. \"These biscuits were detected and seized only because the peddlers were carrying another drug, which was detected in the scanning machine,\" an officer said. This was revealed after Task Force arrested nine people carrying LSD-laced biscuits.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[2:10][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "traget_enc_test = tokenizer.prepare_seq2seq_batch(y_test[0:2], truncation=True, padding='longest', return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['US President Barack Obama has declared January 16 as Religious Freedom Day in accordance with a yearly tradition. Urging his countrymen to stand against religious intolerance, Obama said, \"religious freedom is a principle based not on shared ancestry, culture, ethnicity, or faith but on a shared commitment to liberty.\" He further said that America\\'s strength comes from its diversity.',\n",
       " \"The Supreme Court on Thursday rejected a petition seeking a stay on the release of Madhur Bhandarkar's directorial 'Indu Sarkar'. The court noted that the film is an artistic expression within the parameters of law. The petition was filed by Priya Singh Paul, who claimed to be the daughter of Sanjay Gandhi and was alleging that the movie is derogatory.\",\n",
       " 'Congress leader Captain Amarinder Singh will take oath as the Chief Minister of Punjab on March 16, after he led his party to victory in the Punjab elections, winning 77 of 117 seats. Stating that Prime Minister Narendra Modi had talked to him after the election results, Singh said PM Modi promised to help him with the state.',\n",
       " 'Television actress Kamya Punjabi has claimed in a tweet that hackers removed a \\'backless\\' picture of hers from Instagram. In the picture, Kamya can be seen posing with a lipstick to promote the film \\'Lipstick Under My Burkha\\'. She tweeted, \"Never posted something I never believed in. Never took off something that I once posted... Happy hacking!\"n',\n",
       " \"Souvenirs based on veteran actor Dilip Kumar's films were auctioned for over ?8 lakh. The highest bid was for a souvenir based on Dilip's 1967 film Ram Aur Shyam while a 12-sheeter teaser of Kranti (1981) was auctioned for ?3 lakh. Other souvenirs which were auctioned included an Aamir Khan poster, depicting him as Mangal Pandey. \",\n",
       " 'The Delhi government has approved ?54.84 crore for construction of the longest skywalk in the city, that will connect Tilak Marg railway station to ITO Metro station. \"There are over 25 offices at ITO, besides two Metro stations. The heavy traffic volume and crowd makes it an accident-prone area for pedestrians,\" explained a PWD official. ',\n",
       " 'Drug peddlers are coating biscuits and nut crackers with Lysergic acid diethylamide (LSD) drug to avoid being caught at airports, Task Force officials said. \"These biscuits were detected and seized only because the peddlers were carrying another drug, which was detected in the scanning machine,\" an officer said. This was revealed after Task Force arrested nine people carrying LSD-laced biscuits.',\n",
       " 'Delhi Chief Minister Arvind Kejriwal has received two death threats on his official e-mail, according to the Delhi Police. They also added that the Delhi government has approached Police Commissioner Alok Verma, who then directed the Crime Branch to investigate the matter. Police have been verifying the alleged death threat to the Delhi CM, reports claimed.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[2:10][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173897c1975744a4a4f0380ce0bc4cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(10)):\n",
    "    sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'python' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-45a3ce2a2cc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'python' is not defined"
     ]
    }
   ],
   "source": [
    "python.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(encoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.Tensor([1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1], dtype=torch.uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'bfloat16'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-0b79318ec2ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'bfloat16'"
     ]
    }
   ],
   "source": [
    "torch.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.bfloat16 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
